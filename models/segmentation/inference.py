"""–ò–Ω—Ñ–µ—Ä–µ–Ω—Å –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."""

import torch
import cv2
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from train import UNetWithAttention, PoreDataset, calculate_metrics


def load_model(checkpoint_path: str, device: torch.device):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å."""
    model = UNetWithAttention(in_channels=1, out_channels=1, init_features=32)
    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)
    model.load_state_dict(checkpoint["model_state_dict"])
    model.to(device)
    model.eval()
    print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑: {checkpoint_path}")
    print(f"   –≠–ø–æ—Ö–∞: {checkpoint['epoch']}")
    print(f"   Best Dice: {checkpoint['best_val_dice']:.4f}")
    return model


def predict_image(model, image_path: str, device: torch.device):
    """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if img is None:
        raise FileNotFoundError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path}")
    
    img_norm = img.astype(np.float32) / 255.0
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä
    img_tensor = torch.from_numpy(img_norm).unsqueeze(0).unsqueeze(0).to(device)
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    with torch.no_grad():
        pred = model(img_tensor)
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ
    pred_mask = pred.squeeze().cpu().numpy()
    pred_binary = (pred_mask > 0.5).astype(np.uint8) * 255
    
    return img, pred_mask, pred_binary


def visualize_results(noisy, mask_prob, mask_binary, ground_truth=None, save_path=None):
    """–í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã."""
    num_plots = 3 if ground_truth is None else 4
    fig, axes = plt.subplots(1, num_plots, figsize=(5*num_plots, 5))
    
    axes[0].imshow(noisy, cmap='gray')
    axes[0].set_title('Noisy Input', fontsize=14)
    axes[0].axis('off')
    
    axes[1].imshow(mask_prob, cmap='jet', vmin=0, vmax=1)
    axes[1].set_title('Predicted Mask (Probability)', fontsize=14)
    axes[1].axis('off')
    cbar1 = plt.colorbar(axes[1].images[0], ax=axes[1], fraction=0.046)
    cbar1.set_label('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å', rotation=270, labelpad=15)
    
    axes[2].imshow(mask_binary, cmap='gray')
    axes[2].set_title('Predicted Mask (Binary)', fontsize=14)
    axes[2].axis('off')
    
    if ground_truth is not None:
        axes[3].imshow(ground_truth, cmap='gray')
        axes[3].set_title('Ground Truth', fontsize=14)
        axes[3].axis('off')
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {save_path}")
    
    plt.close()


def evaluate_test_set(model, dataset_dir: str, device: torch.device, num_samples: int = 10):
    """–û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ."""
    test_dataset = PoreDataset(dataset_dir, split="test", augment=False)
    
    output_dir = Path("./results")
    output_dir.mkdir(exist_ok=True)
    
    print(f"\n{'='*70}")
    print(f"–û–¶–ï–ù–ö–ê –ù–ê –¢–ï–°–¢–û–í–û–ú –ù–ê–ë–û–†–ï")
    print(f"{'='*70}\n")
    print(f"–í—Å–µ–≥–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ: {len(test_dataset)}")
    print(f"–ë—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {min(num_samples, len(test_dataset))}\n")
    
    all_dice_scores = []
    all_iou_scores = []
    
    for i in range(min(num_samples, len(test_dataset))):
        noisy_tensor, gt_tensor = test_dataset[i]
        noisy_tensor = noisy_tensor.unsqueeze(0).to(device)
        gt_tensor = gt_tensor.unsqueeze(0).to(device)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        with torch.no_grad():
            pred = model(noisy_tensor)
        
        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        metrics = calculate_metrics(pred, gt_tensor)
        all_dice_scores.append(metrics["dice"])
        all_iou_scores.append(metrics["iou"])
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        noisy_np = (noisy_tensor.squeeze().cpu().numpy() * 255).astype(np.uint8)
        pred_prob = pred.squeeze().cpu().numpy()
        pred_binary = (pred_prob > 0.5).astype(np.uint8) * 255
        gt_np = (gt_tensor.squeeze().cpu().numpy() * 255).astype(np.uint8)
        
        # –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º
        save_path = output_dir / f"test_sample_{i:03d}.png"
        visualize_results(noisy_np, pred_prob, pred_binary, gt_np, save_path=save_path)
        
        print(f"Sample {i:03d}: Dice = {metrics['dice']:.4f}, IoU = {metrics['iou']:.4f}, "
              f"Porosity Error = {metrics['porosity_error']:.4f}")
    
    # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print(f"\n{'='*70}")
    print(f"–ò–¢–û–ì–û–í–´–ï –ú–ï–¢–†–ò–ö–ò")
    print(f"{'='*70}")
    print(f"–°—Ä–µ–¥–Ω–∏–π Dice Score: {np.mean(all_dice_scores):.4f} ¬± {np.std(all_dice_scores):.4f}")
    print(f"–°—Ä–µ–¥–Ω–∏–π IoU:        {np.mean(all_iou_scores):.4f} ¬± {np.std(all_iou_scores):.4f}")
    print(f"{'='*70}\n")


def predict_custom_image(model, image_path: str, device: torch.device, output_path: str = None):
    """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
    print(f"\n–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {image_path}")
    
    noisy, pred_prob, pred_binary = predict_image(model, image_path, device)
    
    if output_path is None:
        output_path = Path(image_path).stem + "_result.png"
    
    visualize_results(noisy, pred_prob, pred_binary, save_path=output_path)
    
    # –í—ã—á–∏—Å–ª—è–µ–º –ø–æ—Ä–∏—Å—Ç–æ—Å—Ç—å
    porosity = (pred_binary == 255).sum() / pred_binary.size
    print(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –ø–æ—Ä–∏—Å—Ç–æ—Å—Ç—å: {porosity:.2%}")


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="–ò–Ω—Ñ–µ—Ä–µ–Ω—Å –º–æ–¥–µ–ª–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø–æ—Ä")
    parser.add_argument(
        "--model",
        type=str,
        default="./checkpoints/best_model.pth",
        help="–ü—É—Ç—å –∫ —á–µ–∫–ø–æ–∏–Ω—Ç—É –º–æ–¥–µ–ª–∏"
    )
    parser.add_argument(
        "--dataset",
        type=str,
        default="./dataset",
        help="–ü—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É –¥–ª—è –æ—Ü–µ–Ω–∫–∏"
    )
    parser.add_argument(
        "--num-samples",
        type=int,
        default=10,
        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏"
    )
    parser.add_argument(
        "--image",
        type=str,
        default=None,
        help="–ü—É—Ç—å –∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"
    )
    
    args = parser.parse_args()
    
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {DEVICE}\n")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    model = load_model(args.model, DEVICE)
    
    if args.image:
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        predict_custom_image(model, args.image, DEVICE)
    else:
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ
        evaluate_test_set(model, args.dataset, DEVICE, num_samples=args.num_samples)


if __name__ == "__main__":
    main()

