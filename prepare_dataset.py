"""–°–∫—Ä–∏–ø—Ç –¥–ª—è —É–ø–∞–∫–æ–≤–∫–∏ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏."""

import json
import os
import shutil
from pathlib import Path
from typing import Literal
import random


class DatasetPreparer:
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏."""
    
    def __init__(
        self,
        clean_dir: str = "./output/clean_background",
        noisy_dir: str = "./output/noisy_background",
        output_dir: str = "./dataset",
        train_ratio: float = 0.7,
        val_ratio: float = 0.15,
        test_ratio: float = 0.15,
    ):
        """
        Args:
            clean_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å —á–∏—Å—Ç—ã–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
            noisy_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –∑–∞—à—É–º–ª–µ–Ω–Ω—ã–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
            output_dir: –í—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞
            train_ratio: –î–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            val_ratio: –î–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            test_ratio: –î–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        self.clean_dir = Path(clean_dir)
        self.noisy_dir = Path(noisy_dir)
        self.output_dir = Path(output_dir)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å—É–º–º–∞ –¥–æ–ª–µ–π = 1
        assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, \
            "–°—É–º–º–∞ train_ratio, val_ratio –∏ test_ratio –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Ä–∞–≤–Ω–∞ 1.0"
        
        self.train_ratio = train_ratio
        self.val_ratio = val_ratio
        self.test_ratio = test_ratio
    
    def prepare_folder_structure(self) -> dict:
        """
        –°–æ–∑–¥–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫ –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.
        
        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–∞—Ç–∞—Å–µ—Ç—É
        """
        print("\n" + "=" * 70)
        print("–ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–¢–ê–°–ï–¢–ê")
        print("=" * 70)
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–∫–∏ —Ñ–∞–π–ª–æ–≤
        clean_files = sorted(self.clean_dir.glob("*_clean.png"))
        noisy_files = sorted(self.noisy_dir.glob("*_noisy.png"))
        
        print(f"\n–ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:")
        print(f"  - –ß–∏—Å—Ç—ã—Ö: {len(clean_files)}")
        print(f"  - –ó–∞—à—É–º–ª–µ–Ω–Ω—ã—Ö: {len(noisy_files)}")
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—ã —Ñ–∞–π–ª–æ–≤
        pairs = self._create_pairs(clean_files, noisy_files)
        print(f"\n–°–æ–∑–¥–∞–Ω–æ –ø–∞—Ä: {len(pairs)}")
        
        if len(pairs) == 0:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–∞—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π!")
            return {}
        
        # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º –ø–∞—Ä—ã
        random.shuffle(pairs)
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/val/test
        splits = self._split_data(pairs)
        
        # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫
        self._create_directories()
        
        # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã
        stats = self._copy_files(splits)
        
        # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        self._create_metadata(stats, splits)
        
        print("\n" + "=" * 70)
        print("‚úÖ –î–ê–¢–ê–°–ï–¢ –ü–û–î–ì–û–¢–û–í–õ–ï–ù!")
        print("=" * 70)
        self._print_stats(stats)
        
        return stats
    
    def _create_pairs(self, clean_files: list, noisy_files: list) -> list:
        """–°–æ–∑–¥–∞–µ—Ç –ø–∞—Ä—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤."""
        pairs = []
        
        # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        clean_dict = {f.stem.replace("_clean", ""): f for f in clean_files}
        noisy_dict = {f.stem.replace("_noisy", ""): f for f in noisy_files}
        
        # –ù–∞—Ö–æ–¥–∏–º –ø–∞—Ä—ã
        for key in clean_dict:
            if key in noisy_dict:
                pairs.append({
                    "clean": clean_dict[key],
                    "noisy": noisy_dict[key],
                    "id": key
                })
        
        return pairs
    
    def _split_data(self, pairs: list) -> dict:
        """–†–∞–∑–¥–µ–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –Ω–∞ train/val/test."""
        total = len(pairs)
        train_size = int(total * self.train_ratio)
        val_size = int(total * self.val_ratio)
        
        return {
            "train": pairs[:train_size],
            "val": pairs[train_size:train_size + val_size],
            "test": pairs[train_size + val_size:]
        }
    
    def _create_directories(self):
        """–°–æ–∑–¥–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π."""
        for split in ["train", "val", "test"]:
            for subdir in ["clean", "noisy"]:
                dir_path = self.output_dir / split / subdir
                dir_path.mkdir(parents=True, exist_ok=True)
    
    def _copy_files(self, splits: dict) -> dict:
        """–ö–æ–ø–∏—Ä—É–µ—Ç —Ñ–∞–π–ª—ã –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏."""
        stats = {"train": 0, "val": 0, "test": 0}
        
        for split_name, pairs in splits.items():
            print(f"\n–ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ {split_name}...")
            for pair in pairs:
                # –ö–æ–ø–∏—Ä—É–µ–º clean
                clean_dest = self.output_dir / split_name / "clean" / pair["clean"].name
                shutil.copy2(pair["clean"], clean_dest)
                
                # –ö–æ–ø–∏—Ä—É–µ–º noisy
                noisy_dest = self.output_dir / split_name / "noisy" / pair["noisy"].name
                shutil.copy2(pair["noisy"], noisy_dest)
                
                stats[split_name] += 1
        
        return stats
    
    def _create_metadata(self, stats: dict, splits: dict):
        """–°–æ–∑–¥–∞–µ—Ç —Ñ–∞–π–ª—ã –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö."""
        metadata = {
            "total_pairs": sum(stats.values()),
            "splits": stats,
            "ratios": {
                "train": self.train_ratio,
                "val": self.val_ratio,
                "test": self.test_ratio
            },
            "files": {}
        }
        
        for split_name, pairs in splits.items():
            metadata["files"][split_name] = [
                {
                    "id": pair["id"],
                    "clean": str(pair["clean"].name),
                    "noisy": str(pair["noisy"].name)
                }
                for pair in pairs
            ]
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON
        metadata_path = self.output_dir / "metadata.json"
        with open(metadata_path, "w", encoding="utf-8") as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        print(f"\nüìÑ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {metadata_path}")
    
    def _print_stats(self, stats: dict):
        """–í—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É."""
        total = sum(stats.values())
        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞:")
        print(f"  –í—Å–µ–≥–æ –ø–∞—Ä: {total}")
        print(f"  Train: {stats['train']} ({stats['train']/total*100:.1f}%)")
        print(f"  Val: {stats['val']} ({stats['val']/total*100:.1f}%)")
        print(f"  Test: {stats['test']} ({stats['test']/total*100:.1f}%)")
        print(f"\nüìÅ –î–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {self.output_dir.absolute()}")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    preparer = DatasetPreparer(
        clean_dir="./output/clean_background",
        noisy_dir="./output/noisy_background",
        output_dir="./dataset",
        train_ratio=0.7,
        val_ratio=0.15,
        test_ratio=0.15
    )
    
    preparer.prepare_folder_structure()


if __name__ == "__main__":
    main()

